# MAF Pattern Integration

## Current Usage

- **Sequential / Handoff Pattern** drives the core pipeline: Multimodal Processor ‚Üí Sentiment ‚Üí Summarizer ‚Üí Analytics. Each agent receives enriched context from the previous step (transcripts, metadata, intermediate findings).
- **ReAct Planner** (Planner agent) analyzes uploaded files and objectives, then assembles the step list stored in Cosmos DB. Reasoning traces show Observe ‚Üí Think ‚Üí Act ‚Üí Reflect loops.
- **Group Collaboration (optional)**: For complex analyses the orchestrator can invite multiple agents to comment on shared context before synthesizing results; hooks exist in the task orchestrator for future group chat scenarios.

## Data Hand-off Details

```python
extracted_content = execution_context.setdefault("extracted_content", {})
extracted_content[file_id] = {
  "transcription": transcript,
  "text_content": text,
  "metadata": metadata_dict,
}

# Downstream agents pull the real transcript
combined_text = "\n\n".join(
  content.get("transcription", "")
  for content in extracted_content.values()
  if content.get("transcription")
)
```

- Multimodal processor writes actual Speech-to-Text and Document Intelligence outputs.
- Sentiment, summarizer, and analytics agents consume the same serialized content‚Äîno mock data involved.

## Key Implementation Files

- `backend/app/services/task_orchestrator.py` ‚Äì Executes plans, logs pattern usage, updates context between steps.
- `backend/app/agents/` ‚Äì Individual agent implementations referencing Azure services.
- `backend/app/main.py` ‚Äì Entry point that wires planner, orchestrator, and persistence.

## Future Enhancements

1. **Concurrent Fan-out** ‚Äì After content extraction, run Sentiment, Summarizer, and Analytics in parallel using `ConcurrentBuilder`.
2. **GroupChat Summaries** ‚Äì Allow sentiment and analytics agents to debate findings before the summarizer finalizes outputs.
3. **Hierarchical Plans** ‚Äì Extend planner to spawn nested workflows for large document batches.

These refinements can be layered on without rewriting the existing sequential baseline thanks to the modular MAF architecture.
# Microsoft Agent Framework Pattern Integration

## Overview
This document explains how the Multimodal Insights Application uses MAF (Microsoft Agent Framework) orchestration patterns for execution.

## Current Architecture

### 1. Sequential Execution with Context Handoff

The application uses **MAF's Sequential Pattern (HandoffPattern)** for executing analysis workflows:

```
Multimodal Processor ‚Üí Sentiment Agent ‚Üí Summarizer Agent ‚Üí Analytics Agent
        ‚Üì                      ‚Üì                   ‚Üì                ‚Üì
    Extract Content      Use Transcript      Use Transcript    Use Transcript
```

**Key Benefits:**
- ‚úÖ Each agent receives context from previous steps
- ‚úÖ Real transcript data flows through the pipeline
- ‚úÖ Proper sequential dependencies maintained
- ‚úÖ Context accumulator pattern for data sharing

### 2. Execution Flow

#### Step 1: File Processing (Multimodal Processor Agent)
**Input:** Uploaded files (audio, video, PDF)
**Output:**
```json
{
  "processed_files": 1,
  "results": {
    "file_id_123": {
      "file_type": "audio",
      "transcription": "Hello, this is the actual speech-to-text transcript...",
      "text_content": "Hello, this is the actual speech-to-text transcript...",
      "audio_metadata": {
        "language": "en-US",
        "format": ".wav"
      },
      "extraction_metadata": {
        "service": "Azure Speech-to-Text"
      }
    }
  }
}
```

**Context Updated:**
```python
execution_context["extracted_content"]["file_id_123"] = {
    "transcription": "...",
    "text_content": "...",
    ...
}
```

#### Step 2-4: Analysis Agents (Sentiment, Summarizer, Analytics)
**Input:** Context from Step 1 containing real transcript
**Process:**
```python
# Extract transcript from context
extracted_content = context.get("extracted_content", {})
all_text = []
for file_id, content in extracted_content.items():
    if content.get("transcription"):
        all_text.append(content["transcription"])  # Using REAL transcript!

combined_text = "\n\n".join(all_text)
```

**Output:** Analysis results based on actual transcript data

### 3. Code Location

**Orchestrator:** `backend/app/services/task_orchestrator.py`

**Key Methods:**
- `execute_plan()` - Uses MAF Sequential Pattern with logging
- `_execute_step()` - Executes individual agent and updates context
- `_execute_multimodal_processing()` - Processes files and stores in context
- `_execute_sentiment_analysis()` - Extracts transcript from context
- `_execute_summarization()` - Extracts transcript from context
- `_execute_analytics()` - Extracts transcript from context

### 4. Logging Pattern Usage

The orchestrator explicitly logs MAF pattern usage:

```python
logger.info("Using MAF HandoffPattern for sequential agent execution")

logger.info(
    f"Context passed to next step",
    extracted_files=len(execution_context.get("extracted_content", {})),
    has_sentiment=bool(execution_context.get("sentiment_results")),
    has_summary=bool(execution_context.get("summary_results")),
    has_analytics=bool(execution_context.get("analytics_results"))
)
```

## Data Flow Verification

### ‚úÖ Confirmed: Real Transcript Data is Used

**Evidence:**
1. `multimodal_processor_agent.py` line 150-165: Generates real transcription using Azure Speech-to-Text
2. `task_orchestrator.py` line 470-490: Sentiment agent extracts `content.get("transcription")`
3. `task_orchestrator.py` line 495-520: Summarizer agent extracts `content.get("transcription")`
4. `task_orchestrator.py` line 525-550: Analytics agent extracts `content.get("transcription")`

**NOT using mock data** - All analysis is performed on actual speech-to-text output!

## UI Improvements

### New Display Features

**Multimodal Processor Results** now show:
- üìÑ File type badges (Audio/Video/PDF)
- üìù Full transcript text with scrollable view
- üéµ Audio metadata (language, format)
- üìä PDF metadata (page count, tables)
- üîß Processing service used (Azure Speech-to-Text, Document Intelligence)

**Analysis Results** continue to show:
- Sentiment scores and emotions
- Summaries with different detail levels
- Analytics insights and recommendations

## Future Enhancements

### Potential Pattern Upgrades

1. **Concurrent Pattern for Analysis Agents**
   - Run Sentiment, Summarizer, Analytics in parallel after file processing
   - Reduce total execution time
   - Use `GroupChatPattern` or concurrent execution

2. **ReAct Pattern for Dynamic Planning**
   - Let planner adjust steps based on file content
   - Add/remove analysis agents dynamically
   - Use `ReActPattern` for adaptive execution

3. **Hierarchical Orchestration**
   - Main orchestrator for workflow
   - Sub-orchestrators for specialized tasks
   - Use nested patterns for complex scenarios

## References

- Framework Patterns: `framework/patterns/`
- Orchestrator Core: `framework/core/orchestrator.py`
- Dynamic Planner: `framework/core/planning.py`
